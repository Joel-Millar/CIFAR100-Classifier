{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVAlfWloWyB5",
    "outputId": "fabec369-80bf-479f-d6ec-641b1e80056f"
   },
   "outputs": [],
   "source": [
    "# Classify the CIFAR100 dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "s9G57G_xWyB6",
    "outputId": "27db2fb6-ffd0-453d-babd-73b7a3010144"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='data', train=True, download=True)\n",
    "\n",
    "DATA_MEANS = (train_dataset.data / 255.0).mean(axis=(0, 1, 2))\n",
    "DATA_STD = (train_dataset.data / 255.0).std(axis=(0, 1, 2))\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(DATA_MEANS, DATA_STD)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(DATA_MEANS, DATA_STD)\n",
    "])\n",
    "\n",
    "train_set = datasets.CIFAR100(root='data', train=True, transform=train_transform, download=True)\n",
    "test_set = datasets.CIFAR100(root='data', train=False, transform=test_transform, download=True)\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='data', train=True, transform=train_transform, download=True)\n",
    "val_dataset = datasets.CIFAR100(root='data', train=True, transform=test_transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3), padding=1)\n",
    "        self.dropout_2d = nn.Dropout2d(p=0.25)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 20, 128)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, 100)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout_2d(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = self.dropout_2d(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        x = x.view(-1, 7 * 7 * 20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.start = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "        self.next_layer = nn.Sequential(\n",
    "              nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "              nn.BatchNorm2d(128),\n",
    "              nn.ReLU(inplace=False)\n",
    ")\n",
    "\n",
    "        self.inception1 = Inception_Block(64, 32, 64, 64, 64, 64, 32)\n",
    "        self.skip1 = Skip_Block(dense=False, a=True, in_channels=192, out1=64, out2=64, out3=128)\n",
    "        self.inception2 = Inception_Block(128, 64, 128, 128, 128, 128, 64)\n",
    "        self.skip2 = Skip_Block(dense=True, a=False, in_channels=384, out1=128, out2=128, out3=256)\n",
    "        self.inception3 = Inception_Block(256, 128, 256, 256, 256, 256, 128)\n",
    "        self.skip3 = Skip_Block(dense=True, a=True, in_channels=768, out1=256, out2=256, out3=512)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.start(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.skip1(x)\n",
    "        x = self.next_layer(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.skip2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.inception3(x)\n",
    "        x = self.skip3(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class Inception_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_one, out_two_prog, out_two, out_three_prog, out_three, out_four):\n",
    "        super(Inception_Block, self).__init__()\n",
    "\n",
    "        self.band1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_one, kernel_size=1),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "        self.band2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_two_prog, kernel_size=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(out_two_prog, out_two, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "        self.band3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_three_prog, kernel_size=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(out_three_prog, out_three, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "        self.band4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_channels, out_four, kernel_size=1),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.band1(x)\n",
    "        out2 = self.band2(x)\n",
    "        out3 = self.band3(x)\n",
    "        out4 = self.band4(x)\n",
    "\n",
    "        output = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "        return output\n",
    "\n",
    "class Skip_Block(nn.Module):\n",
    "    def __init__(self, dense, a, in_channels, out1, out2, out3):\n",
    "        super(Skip_Block, self).__init__()\n",
    "        self.a = a\n",
    "        self.dense = dense\n",
    "        self.path = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out1, kernel_size=1),\n",
    "            nn.BatchNorm2d(out1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(out1, out2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out2),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(out2, out3, kernel_size=1),\n",
    "            nn.BatchNorm2d(out3)\n",
    "        )\n",
    "\n",
    "        self.base = nn.Sequential(nn.Conv2d(in_channels, out3, kernel_size=1),\n",
    "                             nn.BatchNorm2d(out3)\n",
    "                             )\n",
    "\n",
    "        self.setup = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out3, kernel_size=1),\n",
    "            nn.BatchNorm2d(out3)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.dense:\n",
    "            if self.a:\n",
    "                out = torch.cat([self.path(x), self.base(x)], dim=1)\n",
    "            else:\n",
    "                out = torch.cat([self.path(x) + self.base(x)], dim=1)\n",
    "            return out\n",
    "        else:\n",
    "          if self.a:\n",
    "              out = self.path(x) + self.base(x)\n",
    "          else:\n",
    "              out = self.path(x) + self.setup(x)\n",
    "          out = F.relu(out)\n",
    "          return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "HLZJd2u6WyB8",
    "outputId": "127bc2f1-3bac-4221-cb36-ca8873f930f8"
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model()\n",
    "model = model.to(device)\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "weight_decay = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=3, last_epoch=-1)\n",
    "\n",
    "def train():\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.\n",
    "        last_loss = 0.\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            l = loss(outputs, labels)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += l.item()\n",
    "        running_loss = running_loss / len(train_loader)\n",
    "        print('Epoch: ' + str(epoch) + ' Loss: ' + str(running_loss))\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    return last_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            l = loss(outputs, labels)\n",
    "            test_loss += l.item()\n",
    "\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "    return test_loss / len(test_loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xa1QxtqFJANJ",
    "outputId": "c82d9bfc-579c-4d12-982b-d88975580394"
   },
   "outputs": [],
   "source": [
    "for epoch in range(0, epochs):\n",
    "    train_loss = train()\n",
    "    test_loss, test_accuracy = test()\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
